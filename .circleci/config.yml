version: 2
jobs:
  build: 
    docker:
      - image: palantirtechnologies/circle-spark
    steps:
      - checkout
      - run: "[[ ! -s \"$(git rev-parse --git-dir)/shallow\" ]] || git fetch --unshallow"
      - run: echo "user=$BINTRAY_USERNAME" > .credentials
      - run: echo "password=$BINTRAY_PASSWORD" >> .credentials
      - run: echo "realm=Bintray API Realm" >> .credentials
      - run: echo "host=api.bintray.com" >> .credentials
      - restore_cache:
          key: dependency-cache-{{ checksum "pom.xml" }}
      - run: set -o pipefail && ./build/mvn -DskipTests -Phadoop-cloud -Phadoop-palantir -Pkinesis-asl -Pkubernetes -Pyarn -Phive -Psparkr install | tee -a "$CIRCLE_ARTIFACTS/mvn-install.log"
      - run: |
          # Make sbt fetch all the external deps to ~/.ivy2 so it gets cached
          set -o pipefail && ./build/sbt -Phadoop-cloud -Phadoop-palantir -Pkinesis-asl -Pkubernetes -Pyarn -Phive -Psparkr externalDependencyClasspath | tee -a "$CIRCLE_ARTIFACTS/sbt-classpath.log"
      - save_cache:
          key: dependency-cache-{{ checksum "pom.xml" }}
          paths:
            - "~/.ivy2"
            - "~/.m2"
    environment:
      - TERM: dumb

  test:
    docker:
      - image: palantirtechnologies/circle-spark
    # project/CirclePlugin.scala does its own test splitting in SBT based on CIRCLE_NODE_INDEX, CIRCLE_NODE_TOTAL
    parallelism: 6
    # Spark runs a lot of tests in parallel, we need 16 GB of RAM for this
    resource_class: xlarge
    steps:
      - run: set -o pipefail && HADOOP_PROFILE=hadooppalantir ./dev/run-tests | tee -a "$CIRCLE_ARTIFACTS/run-tests.log"
      - run: find . -name unit-tests.log -exec rsync -R {} $CIRCLE_ARTIFACTS \;
      - run: |
                shopt -s nullglob
                files=(resource-managers/yarn/target/./org.apache.spark.deploy.yarn.*/*-logDir-*)
                if [[ ${#files[@]} != 0 ]]; then
                  rsync -Rrm "${files[@]}" $CIRCLE_ARTIFACTS
                fi
  deploy:
    docker:
      - image: palantirtechnologies/circle-spark
    steps:
      - run: dev/publish.sh
      - run: curl -u $BINTRAY_USERNAME:$BINTRAY_PASSWORD -X POST https://api.bintray.com/content/palantir/releases/spark/$(git describe --tags)/publish

workflows:
  version: 2
  build-test-deploy:
    jobs:
      - build:
          filters:
            # run on all branches and tags
            tags:
              only: /.*/
      - test:
          requires:
            - build
          filters:
            # run on all branches and tags
            tags:
              only: /.*/
      - deploy:
          requires:
            - build
            - test
          filters:
            tags:
              only: /[0-9]+(?:\.[0-9]+){2,}-palantir\.[0-9]+(?:\.[0-9]+)*/
            branches:
              only: master
